{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyEC4SqzoNLx"
      },
      "source": [
        "# Topic Explainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3RavYOEAqRpN"
      },
      "outputs": [],
      "source": [
        "!pip install -q anthropic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7N5mwBloKSz"
      },
      "outputs": [],
      "source": [
        "import anthropic\n",
        "import openai\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrK1BzVoq_YM"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "openai = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
        "claude = anthropic.Anthropic(api_key= userdata.get('ANTHROPIC_API_KEY'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GltaNWW6rZ22"
      },
      "outputs": [],
      "source": [
        "system_message = \"You are a well known teacher who is known to explain any topic in very simple and structured way , you first give a 2-3 line introduction about the topic , then you give some important bullet points related to it then\\\n",
        "followed by a simple and short example related to that topic\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuMv6tFzraOu"
      },
      "outputs": [],
      "source": [
        "system_message += \"/n The user tells you which class they study in along with the topic , and then explain the topic in deapth according to their level of knowledge , example a student can be of class 8,9,10,11,12 or in graduation , or maybe doing a PhD\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEc1--cHUis6"
      },
      "outputs": [],
      "source": [
        "system_message += \"/n Make sure the language is very simple and avoid using complex terms where-ever possible\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVcrIF_ryxp3"
      },
      "outputs": [],
      "source": [
        "system_message += \"\\n always respond in markdown\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyvs_TiPtx-5"
      },
      "outputs": [],
      "source": [
        "def stream_gpt(prompt):\n",
        "    message = [\n",
        "        {\"role\" : \"system\" , \"content\" : system_message},\n",
        "        {\"role\" : \"user\" , \"content\" : prompt}\n",
        "    ]\n",
        "    response = openai.chat.completions.create(\n",
        "        model = 'gpt-4o',\n",
        "        messages = message,\n",
        "        stream = True\n",
        "    )\n",
        "    result = \"\"\n",
        "    for chunk in response:\n",
        "        result += chunk.choices[0].delta.content or \"\"\n",
        "        yield result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_Z0fyrvtyE9"
      },
      "outputs": [],
      "source": [
        "def stream_claude(prompt):\n",
        "    response = claude.messages.stream(\n",
        "        model = 'claude-3-5-sonnet-20240620',\n",
        "        max_tokens = 1000,\n",
        "        system = system_message,\n",
        "        messages = [\n",
        "            {\"role\" : \"user\" , \"content\" : prompt}\n",
        "        ]\n",
        "    )\n",
        "    result = \"\"\n",
        "    with response as stream:\n",
        "        for text in stream.text_stream:\n",
        "            result += text or \"\"\n",
        "            yield result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alGU70cztyJa"
      },
      "outputs": [],
      "source": [
        "def stream_model(prompt, model):\n",
        "    if model == \"GPT\":\n",
        "        result = stream_gpt(prompt)\n",
        "    elif model == \"Claude\":\n",
        "        result = stream_claude(prompt)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown Model\")\n",
        "\n",
        "    for chunk in result:\n",
        "        yield chunk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQMoMtr4oQ0s"
      },
      "source": [
        "# ChatBot for Q&A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIrmA0XVtxR3"
      },
      "outputs": [],
      "source": [
        "system_message2 = \"system_message = You are a well known teacher , when someone gives you a topic you give them 5 MCQ questions one by one , the next question appears after the user have answered the previous \\\n",
        "one , and at the end you give score out of 5 and teach them in short and in easy terms what they did not know about the topic (based on their answers)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-YPAYkvtxVZ"
      },
      "outputs": [],
      "source": [
        "system_message2 += \"\\n your main focus is on Indian High school subjects like science (physics  , chemistry , biology), maths , history , etc\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdIQgArCoVKK"
      },
      "outputs": [],
      "source": [
        "system_message2 += \"\\n in start you just ask in which class do you study ? n, Tell me the topic ? , just like that short and crisp , then questions accordingly (difficulty/deapth of topic according to\\\n",
        "the class they study in)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKmo142CoVr8"
      },
      "outputs": [],
      "source": [
        "def gpt_qna(message, history):\n",
        "    messages = [{\"role\" : \"system\" , \"content\" : system_message2}]\n",
        "    for user_message , assistant_message in history:\n",
        "        messages.append({\"role\" : \"user\" , \"content\" : user_message})\n",
        "        messages.append({\"role\" : \"assistant\" , \"content\" : assistant_message})\n",
        "\n",
        "    messages.append({\"role\" : \"user\" , \"content\" : message})\n",
        "\n",
        "    stream = openai.chat.completions.create(model = 'gpt-4o-mini' , messages = messages, stream = True)\n",
        "    response = \"\"\n",
        "    for chunk in stream:\n",
        "        response += chunk.choices[0].delta.content or ''\n",
        "        yield response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iklVJjj1rOe"
      },
      "outputs": [],
      "source": [
        "def claude_qna(message, history):\n",
        "    messages = []\n",
        "    for user_message , assistant_message in history:\n",
        "        messages.append({\"role\" : \"user\" , \"content\" : user_message})\n",
        "        messages.append({\"role\" : \"assistant\" , \"content\" : assistant_message})\n",
        "\n",
        "    messages.append({\"role\" : \"user\" , \"content\" : message})\n",
        "\n",
        "    response = claude.messages.stream(\n",
        "        model = 'claude-3-5-sonnet-20240620',\n",
        "        max_tokens = 400,\n",
        "        system = system_message2,\n",
        "        messages = messages\n",
        "    )\n",
        "    result = \"\"\n",
        "    with response as stream:\n",
        "        for text in stream.text_stream:\n",
        "            result += text or \"\"\n",
        "            yield result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-989QRToWDE"
      },
      "source": [
        "# Image Generator for explanation\n",
        "### found two models : Recraft and Flux 1.1 pro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9GWwzvU6aGa"
      },
      "outputs": [],
      "source": [
        "# import base64\n",
        "# from io import BytesIO\n",
        "# from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F10KVGKEog58"
      },
      "outputs": [],
      "source": [
        "# def concept_image(city):\n",
        "#     image_response = openai.images.generate(\n",
        "#         model = \"dall-e-3\",\n",
        "#         prompt = f\"Generate an image related to city {city}  , the image should be such that it might help visualise the person reading about{city}\",\n",
        "#         size = \"1024x1024\",\n",
        "#         n=1,\n",
        "#         response_format = 'b64_json'\n",
        "#     )\n",
        "#     image_base64 = image_response.data[0].b64_json\n",
        "#     image_data = base64.b64decode(image_base64)\n",
        "#     return Image.open(BytesIO(image_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oWDchh76aMk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roB9GvdM6aQa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eGw-zzSon91"
      },
      "source": [
        "# Pdf to Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZw-19MYohaJ",
        "outputId": "56f46913-99c3-40e3-aba9-9e03c3cfca39"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pdf_processing'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-2397696fd9e6>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# app.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpdf_processing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextract_text_from_pdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitialize_faiss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_faiss_initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqa_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mretrieve_answer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pdf_processing'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# # app.py\n",
        "# import gradio as gr\n",
        "# from pdf_processing import extract_text_from_pdf\n",
        "# from embeddings import initialize_faiss, is_faiss_initialized\n",
        "# from qa_model import retrieve_answer\n",
        "\n",
        "# def process_pdf_and_answer(pdf, question):\n",
        "#     # Extract text from PDF and initialize FAISS index\n",
        "#     text = extract_text_from_pdf(pdf)\n",
        "#     initialize_faiss(text)\n",
        "\n",
        "#     if not is_faiss_initialized():\n",
        "#         return \"Error: FAISS index failed to initialize.\"\n",
        "#     # Answer the question using retrieval and generation\n",
        "#     answer = retrieve_answer(question)\n",
        "#     return answer\n",
        "\n",
        "# # Define Gradio Inputs and Outputs\n",
        "# pdf_input = gr.File(label=\"Upload PDF\")\n",
        "# question_input = gr.Textbox(label=\"Ask a question about the PDF content\")\n",
        "# output_text = gr.Textbox(label=\"Answer\")\n",
        "\n",
        "# # Create Gradio Interface\n",
        "# interface = gr.Interface(\n",
        "#     fn=process_pdf_and_answer,\n",
        "#     inputs=[pdf_input, question_input],\n",
        "#     outputs=output_text,\n",
        "#     title=\"COGNIFY PDF ANALYZER\",\n",
        "#     description=\"Upload a PDF, and ask questions about its content.\",\n",
        "# )\n",
        "\n",
        "# # Launch the Gradio App\n",
        "# if __name__ == \"__main__\":\n",
        "#     interface.launch(share=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8NaijL3otN8"
      },
      "outputs": [],
      "source": [
        "# # qa_model.py\n",
        "# from embeddings import faiss_index, is_faiss_initialized\n",
        "# from langchain.chains import RetrievalQA\n",
        "# from langchain_huggingface import HuggingFacePipeline\n",
        "# from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "# # Initialize Hugging Face Model for Answer Generation\n",
        "# def load_qa_model():\n",
        "#     \"\"\"\n",
        "#     Loads a Hugging Face pipeline for text generation and wraps it in LangChain.\n",
        "#     \"\"\"\n",
        "#     model_name = 'meta-llama/Llama-3.1-8B'  # Replace with your Hugging Face model\n",
        "#     tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "#     model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "#     # Create a text-generation pipeline\n",
        "#     hf_pipeline = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
        "\n",
        "#     # Wrap the pipeline in LangChain's HuggingFacePipeline\n",
        "#     return HuggingFacePipeline(pipeline=hf_pipeline)\n",
        "\n",
        "# # Load the QA model\n",
        "# qa_model = load_qa_model()\n",
        "\n",
        "# def retrieve_answer(question):\n",
        "#     \"\"\"\n",
        "#     Retrieves an answer for the given question using the FAISS index.\n",
        "\n",
        "#     Args:\n",
        "#         question (str): The question to ask.\n",
        "\n",
        "#     Returns:\n",
        "#         str: The answer retrieved or an error message.\n",
        "#     \"\"\"\n",
        "#     global faiss_index\n",
        "\n",
        "#     # Check if FAISS index is initialized\n",
        "#     if not is_faiss_initialized():\n",
        "#         return \"Error: FAISS index is not initialized.\"\n",
        "\n",
        "#     try:\n",
        "#         retriever = faiss_index.as_retriever()\n",
        "#         qa_chain = RetrievalQA.from_chain_type(llm=qa_model, retriever=retriever)\n",
        "#         response = qa_chain.run(question)\n",
        "#         return response\n",
        "#     except Exception as e:\n",
        "#         return f\"Error during QA retrieval: {e}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XF1esMyKosoD"
      },
      "outputs": [],
      "source": [
        "# # pdf_processing.py\n",
        "# from PyPDF2 import PdfReader\n",
        "\n",
        "# def extract_text_from_pdf(pdf):\n",
        "#     text = \"\"\n",
        "#     pdf_reader = PdfReader(pdf)\n",
        "#     for page in pdf_reader.pages:\n",
        "#         text += page.extract_text()\n",
        "#     return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjkHrEwU_gxx"
      },
      "outputs": [],
      "source": [
        "# # embeddings.py\n",
        "# from sentence_transformers import SentenceTransformer\n",
        "# from langchain_community.vectorstores import FAISS\n",
        "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "# from langchain.docstore.document import Document\n",
        "\n",
        "# # Global FAISS index\n",
        "# faiss_index = None\n",
        "\n",
        "# def initialize_faiss(text):\n",
        "#     \"\"\"\n",
        "#     Initializes a FAISS index with the given text.\n",
        "\n",
        "#     Args:\n",
        "#         text (str): The text to embed and index.\n",
        "#     \"\"\"\n",
        "#     global faiss_index\n",
        "\n",
        "#     if not text:\n",
        "#         print(\"Error: No text provided to initialize FAISS index.\")\n",
        "#         return\n",
        "\n",
        "#     # Initialize Sentence Transformer and HuggingFace embeddings\n",
        "#     hf_embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "#     documents = [Document(page_content=text)]  # Wrap text in LangChain Document\n",
        "\n",
        "#     # Create the FAISS index\n",
        "#     faiss_index = FAISS.from_documents(documents, hf_embeddings)\n",
        "#     print(\"FAISS index initialized successfully.\")\n",
        "\n",
        "# def is_faiss_initialized():\n",
        "#     \"\"\"\n",
        "#     Checks if the FAISS index is initialized.\n",
        "\n",
        "#     Returns:\n",
        "#         bool: True if the FAISS index is initialized, False otherwise.\n",
        "#     \"\"\"\n",
        "#     global faiss_index\n",
        "#     return faiss_index is not None\n",
        "\n",
        "# def query_faiss(query_text):\n",
        "#     \"\"\"\n",
        "#     Queries the FAISS index if it's initialized.\n",
        "\n",
        "#     Args:\n",
        "#         query_text (str): The text to query in the FAISS index.\n",
        "\n",
        "#     Returns:\n",
        "#         list: The query results if the index is initialized, otherwise an error message.\n",
        "#     \"\"\"\n",
        "#     global faiss_index\n",
        "#     if not is_faiss_initialized():\n",
        "#         print(\"Error: FAISS index is not initialized. Please upload a PDF or text first.\")\n",
        "#         return None\n",
        "\n",
        "#     # Assuming FAISS index supports a 'similarity_search' method\n",
        "#     results = faiss_index.similarity_search(query_text)\n",
        "#     return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn3ivu1YoucA"
      },
      "source": [
        "# Image to text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qovmozGNo2G8",
        "outputId": "de2baa10-5b0a-4f10-9cf7-5472624655d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: paddleocr in /usr/local/lib/python3.10/dist-packages (2.9.1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from paddleocr) (2.0.6)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from paddleocr) (0.24.0)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (from paddleocr) (0.4.0)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.10/dist-packages (from paddleocr) (1.3.0.post6)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.10/dist-packages (from paddleocr) (1.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from paddleocr) (4.66.6)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from paddleocr) (1.26.4)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from paddleocr) (3.10.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from paddleocr) (4.10.0.84)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from paddleocr) (4.10.0.84)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from paddleocr) (3.0.11)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from paddleocr) (11.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from paddleocr) (6.0.2)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (from paddleocr) (1.1.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from paddleocr) (4.12.3)\n",
            "Requirement already satisfied: fonttools>=4.24.0 in /usr/local/lib/python3.10/dist-packages (from paddleocr) (4.55.0)\n",
            "Requirement already satisfied: fire>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from paddleocr) (0.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from paddleocr) (2.32.3)\n",
            "Requirement already satisfied: albumentations==1.4.10 in /usr/local/lib/python3.10/dist-packages (from paddleocr) (1.4.10)\n",
            "Requirement already satisfied: albucore==0.0.13 in /usr/local/lib/python3.10/dist-packages (from paddleocr) (0.0.13)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.13->paddleocr) (2.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.13->paddleocr) (4.12.2)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.13->paddleocr) (4.10.0.84)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.10->paddleocr) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.10->paddleocr) (1.5.2)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.10->paddleocr) (2.9.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.3.0->paddleocr) (2.5.0)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image->paddleocr) (3.4.2)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->paddleocr) (2.36.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->paddleocr) (2024.9.20)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->paddleocr) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->paddleocr) (0.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->paddleocr) (2.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug->paddleocr) (1.16.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug->paddleocr) (3.8.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx->paddleocr) (5.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->paddleocr) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->paddleocr) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->paddleocr) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->paddleocr) (2024.8.30)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations==1.4.10->paddleocr) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations==1.4.10->paddleocr) (2.23.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.10->paddleocr) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.10->paddleocr) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->paddleocr) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->paddleocr) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->paddleocr) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->paddleocr) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->paddleocr) (2.8.2)\n",
            "Requirement already satisfied: paddlepaddle in /usr/local/lib/python3.10/dist-packages (2.6.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (0.27.2)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (11.0.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (4.4.2)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (4.25.5)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->paddlepaddle) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->paddlepaddle) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install paddleocr\n",
        "!pip install paddlepaddle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKoFWF-9Mmv6"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from paddleocr import PaddleOCR\n",
        "\n",
        "def ocr_with_paddle(img):\n",
        "    finaltext = ''\n",
        "    ocr = PaddleOCR(lang='en', use_angle_cls=False)\n",
        "    result = ocr.ocr(img)\n",
        "\n",
        "    for i in range(len(result[0])):\n",
        "        text = result[0][i][1][0]\n",
        "        finaltext += ' ' + text\n",
        "    return finaltext\n",
        "\n",
        "def message_for(question):\n",
        "    return [\n",
        "        {\"role\" : \"system\" , \"content\" : system_message},\n",
        "        {\"role\" : \"user\" , \"content\" : f\"can you answer the following question in easy terms : {question}\"}\n",
        "    ]\n",
        "def ask_gpt(question):\n",
        "    response = openai.chat.completions.create(\n",
        "        model = 'gpt-4o-mini' ,\n",
        "        messages = message_for(question)\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "def process_image_and_answer(img):\n",
        "    extracted_text = ocr_with_paddle(img)\n",
        "    gpt_answer = ask_gpt(extracted_text)\n",
        "    return gpt_answer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOeQlIYOMnPi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eZkBfPZMnSN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpeBtqAfo2XZ"
      },
      "source": [
        "# Text Summarizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ciw4zVWBo6Pf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EQ-5c_vo6Ye"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Zmoszj6o7Ci"
      },
      "source": [
        "# UI work (Gradio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7uzwr2RvV7e"
      },
      "outputs": [],
      "source": [
        "!pip install -q gradio\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "id": "QzfYp6QV43ap",
        "outputId": "d84c016b-6bdf-45b3-b3ce-b7508667f4ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://98868a80f9a91eb06f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://98868a80f9a91eb06f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2024/11/21 06:46:47] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/root/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/usr/local/lib/python3.10/dist-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='/root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
            "[2024/11/21 06:46:48] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n",
            "[2024/11/21 06:46:48] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.06280279159545898\n",
            "[2024/11/21 06:46:48] ppocr DEBUG: rec_res num  : 2, elapsed : 0.2646017074584961\n"
          ]
        }
      ],
      "source": [
        "with gr.Blocks() as demo:\n",
        "\n",
        "    with gr.Row():\n",
        "        gr.Image(\"logonew.png\", elem_id=\"logo\", label=None, height=150 )\n",
        "\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            topic_input = gr.Textbox(label=\"Enter your Topic:\", placeholder=\"Type your topic here...\")\n",
        "            model_select = gr.Dropdown([\"GPT\", \"Claude\"], label=\"Select Model\")\n",
        "            topic_output = gr.Markdown(label=\"Topic Explanation\")\n",
        "            explain_button = gr.Button(\"Explain Topic\")\n",
        "\n",
        "        explain_button.click(fn=stream_model, inputs=[topic_input, model_select], outputs=topic_output)\n",
        "\n",
        "\n",
        "        with gr.Column():\n",
        "            custom_chatbot = gr.Chatbot(height=600)\n",
        "            chat_interface = gr.ChatInterface(fn=gpt_qna, chatbot=custom_chatbot)\n",
        "\n",
        "\n",
        "    with gr.Row():\n",
        "        gr.Button(\"Clear\").click(lambda: None, None, [topic_output])\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"### Upload a Question Image for AI Explanation\")\n",
        "            image_input = gr.Image(label=\"Upload Question Image\")\n",
        "            gpt_answer_output = gr.Markdown(label=\"Answer from ChatGPT\")\n",
        "            process_button = gr.Button(\"Process Image\")\n",
        "\n",
        "        process_button.click(fn=process_image_and_answer, inputs=image_input, outputs=gpt_answer_output)\n",
        "\n",
        "\n",
        "    with gr.Row():\n",
        "        gr.Button(\"Clear\").click(lambda: None, None, [topic_output, gpt_answer_output])\n",
        "\n",
        "\n",
        "demo.launch(debug = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1_3jmcz6NSs"
      },
      "outputs": [],
      "source": [
        "# with gr.Blocks() as demo:\n",
        "#     # Row for logo\n",
        "#     with gr.Row():\n",
        "#         gr.Image(\"logonew.png\", elem_id=\"logo\", label=None, height=150 )\n",
        "\n",
        "#     # First Column for Topic Explainer\n",
        "#     with gr.Row():\n",
        "#         with gr.Column():\n",
        "#             topic_input = gr.Textbox(label=\"Enter your Topic:\", placeholder=\"Type your topic here...\")\n",
        "#             model_select = gr.Dropdown([\"GPT\", \"Claude\"], label=\"Select Model\")\n",
        "#             topic_output = gr.Markdown(label=\"Topic Explanation\")\n",
        "#             explain_button = gr.Button(\"Explain Topic\")\n",
        "\n",
        "#         explain_button.click(fn=stream_model, inputs=[topic_input, model_select], outputs=topic_output)\n",
        "\n",
        "#         # Second Column for QnA Chatbot\n",
        "#         with gr.Column():\n",
        "#             custom_chatbot = gr.Chatbot(height=600)\n",
        "#             chat_interface = gr.ChatInterface(fn=gpt_qna, chatbot=custom_chatbot)\n",
        "\n",
        "#     # Clear Button\n",
        "#     with gr.Row():\n",
        "#         gr.Button(\"Clear\").click(lambda: None, None, [topic_output])\n",
        "\n",
        "# demo.launch(debug = True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "t-989QRToWDE",
        "_eGw-zzSon91"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}